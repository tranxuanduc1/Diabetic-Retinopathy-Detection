{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6061886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3579f43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 3.8.0\n",
      "Summary: Multi-backend Keras\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Keras team <keras-users@googlegroups.com>\n",
      "License: Apache License 2.0\n",
      "Location: /home/duc/Documents/DoAn/myvenv/lib/python3.10/site-packages\n",
      "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n",
      "Required-by: tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip show keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adab0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "213464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== CONFIG ==================\n",
    "TRAIN_DIR = \"archive/augmented_resized_V2/train\"\n",
    "VAL_DIR   = \"archive/augmented_resized_V2/val\"\n",
    "\n",
    "IMAGE_SIZE = 448       # 448 hoặc 512 cho CPU; 600 sẽ rất chậm trên CPU\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "FREEZE_BACKBONE = True   # freeze giai đoạn đầu cho CPU\n",
    "DROP_RATE = 0.4          # dropout trong head\n",
    "DENSE_UNITS = 1024\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LOSS_W_SOFTMAX = 1.0\n",
    "LOSS_W_ORDINAL = 0.5\n",
    "\n",
    "EPOCHS = 20              # ví dụ (bạn tăng sau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3674e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c4b0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Ordinal utils ==========\n",
    "def ordinal_encode_tf(y_int):\n",
    "    \"\"\"y_int: (B,) int32 0..4 -> (B,4) float32: [y>=1, y>=2, y>=3, y>=4]\"\"\"\n",
    "    y_int = tf.cast(y_int, tf.int32)\n",
    "    thresholds = tf.constant([1, 2, 3, 4], dtype=tf.int32)  # (4,)\n",
    "    y_exp = tf.expand_dims(y_int, axis=-1)                  # (B,1)\n",
    "    return tf.cast(y_exp >= thresholds, tf.float32)         # (B,4)\n",
    "\n",
    "def map_preprocess(image, label):\n",
    "    # image_dataset_from_directory trả image uint8 [0..255]; EfficientNet preprocess sẽ scale\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = preprocess_input(image)  # -> [0..1] cho EfficientNet\n",
    "    return image, label\n",
    "\n",
    "def map_dual_targets(image, y_int):\n",
    "    # tạo 2 nhãn: softmax (int) và ordinal (4-dim)\n",
    "    return image, {\n",
    "        \"softmax\": tf.cast(y_int, tf.int32),\n",
    "        \"ordinal\": ordinal_encode_tf(y_int)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d8fab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Dataset loaders (không cache vào RAM) ==========\n",
    "def make_ds(data_dir, subset=\"train\"):\n",
    "    ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=[\"0\",\"1\",\"2\",\"3\",\"4\"],   # cố định thứ tự nhãn\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        shuffle=(subset==\"train\"),\n",
    "        seed=SEED\n",
    "    )\n",
    "    ds = ds.map(map_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(map_dual_targets, num_parallel_calls=AUTOTUNE)\n",
    "    # Không dùng .cache() để tiết kiệm RAM; chỉ prefetch\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99119d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sca_block(x, ratio=8, name=\"sca\"):\n",
    "    \"\"\"Simple Channel Attention: GAP -> 1x1 Conv (reduce) -> 1x1 Conv (gate sigmoid) -> multiply.\"\"\"\n",
    "    ch = int(x.shape[-1])\n",
    "    mid = max(ch // ratio, 1)\n",
    "\n",
    "    gap = layers.GlobalAveragePooling2D(keepdims=True, name=f\"{name}_gap\")(x)\n",
    "    red = layers.Conv2D(mid, 1, padding=\"same\", activation=\"relu\",\n",
    "                        use_bias=True, name=f\"{name}_reduce\")(gap)\n",
    "    gate = layers.Conv2D(ch, 1, padding=\"same\", activation=\"sigmoid\",\n",
    "                         use_bias=True, name=f\"{name}_gate\")(red)\n",
    "    out = layers.Multiply(name=f\"{name}_mul\")([x, gate])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e5fdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model builder ==========\n",
    "def build_model(img_size=IMAGE_SIZE, freeze_backbone=FREEZE_BACKBONE):\n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    # Backbone EfficientNet-B4 (ImageNet)\n",
    "    base = EfficientNetB4(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    base.trainable = not freeze_backbone\n",
    "\n",
    "    x = base.output\n",
    "    # CBAM ở feature map cuối (nhẹ)\n",
    "    x = sca_block(x, ratio=8, name=\"sca\")\n",
    "\n",
    "    # Global pooling + head chung\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE)(x)\n",
    "    x = layers.Dense(DENSE_UNITS, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE * 0.75)(x)\n",
    "\n",
    "    # Head A: Softmax 5 lớp\n",
    "    out_soft = layers.Dense(5, activation=\"softmax\", name=\"softmax\")(x)\n",
    "    # Head B: Ordinal (≥1..4), sigmoid\n",
    "    out_ord  = layers.Dense(4, activation=\"sigmoid\", name=\"ordinal\")(x)\n",
    "\n",
    "    model = models.Model(inputs, [out_soft, out_ord], name=\"EffB4_CBAM_DualHead\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24e5b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Compile ==========\n",
    "def compile_model(model,\n",
    "                  lr=LR,\n",
    "                  wd=WEIGHT_DECAY,\n",
    "                  loss_w_softmax=LOSS_W_SOFTMAX,\n",
    "                  loss_w_ordinal=LOSS_W_ORDINAL):\n",
    "    try:\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "    except Exception:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    losses = {\n",
    "        \"softmax\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"ordinal\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    }\n",
    "    loss_weights = {\"softmax\": loss_w_softmax, \"ordinal\": loss_w_ordinal}\n",
    "\n",
    "    metrics = {\n",
    "        \"softmax\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "        \"ordinal\": [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)],\n",
    "    }\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                  loss_weights=loss_weights, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81327a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== MAIN ==================\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "ds_train = make_ds(TRAIN_DIR, subset=\"train\")\n",
    "ds_val   = make_ds(VAL_DIR, subset=\"val\")\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model = compile_model(model)\n",
    "\n",
    "model.summary(line_length=120)\n",
    "\n",
    "    # Giai đoạn 1: (khuyên dùng cho CPU) train head với backbone freeze\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"models/effb4_dualhead_stage1.keras\",\n",
    "                                           monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n=== Stage 1: Train head (backbone frozen) ===\")\n",
    "history1 = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f005a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"effb4_dualhead_stage_13epoch.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1fdbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # bật True nếu muốn fine-tune tiếp   \n",
    "UNFREEZE=True\n",
    "model=tf.keras.models.load_model('models/effb4_dualhead_stage1.keras',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c5313bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpus:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gpu \u001b[38;5;129;01min\u001b[39;00m gpus:\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/framework/config.py:754\u001b[0m, in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_memory_growth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_memory_growth\u001b[39m(device, enable):\n\u001b[1;32m    731\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m   \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1998\u001b[0m, in \u001b[0;36mContext.set_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1995\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1998\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1999\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhysical devices cannot be modified after being initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2000\u001b[0m   )\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_growth_map[dev] \u001b[38;5;241m=\u001b[39m enable\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf, gc\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "# Bật memory growth (rất quan trọng)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "167b4bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfreezing backbone for fine-tuning...\n",
      "\n",
      "=== Stage 2: Fine-tuning (unfrozen) ===\n",
      "Epoch 1/10\n",
      "\u001b[1m12517/12518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: nan - ordinal_auc: 0.4998 - ordinal_loss: nan - softmax_acc: 0.0613 - softmax_loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:12:21.335493: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-10 22:12:21.478373: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12518/12518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: nan - ordinal_auc: 0.4998 - ordinal_loss: nan - softmax_acc: 0.0613 - softmax_loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:15:23.306262: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-10 22:15:23.452547: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12518/12518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2016s\u001b[0m 158ms/step - loss: nan - ordinal_auc: 0.4998 - ordinal_loss: nan - softmax_acc: 0.0613 - softmax_loss: nan - val_loss: nan - val_ordinal_auc: 0.5000 - val_ordinal_loss: nan - val_softmax_acc: 0.0931 - val_softmax_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m12518/12518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1925s\u001b[0m 154ms/step - loss: nan - ordinal_auc: nan - ordinal_loss: nan - softmax_acc: 0.0503 - softmax_loss: nan - val_loss: nan - val_ordinal_auc: nan - val_ordinal_loss: nan - val_softmax_acc: 0.0931 - val_softmax_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m12518/12518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1925s\u001b[0m 154ms/step - loss: nan - ordinal_auc: nan - ordinal_loss: nan - softmax_acc: nan - softmax_loss: nan - val_loss: nan - val_ordinal_auc: nan - val_ordinal_loss: nan - val_softmax_acc: 0.0931 - val_softmax_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m 6775/12518\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13:34\u001b[0m 142ms/step - loss: nan - ordinal_auc: nan - ordinal_loss: nan - softmax_acc: nan - softmax_loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m    model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mlosses,\n\u001b[1;32m     46\u001b[0m                  loss_weights\u001b[38;5;241m=\u001b[39mloss_weights, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     47\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Stage 2: Fine-tuning (unfrozen) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m    history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m           \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m           \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m           \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m           \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m           \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[43m       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDone (xây dựng & compile xong; train cơ bản đã chạy).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # Giai đoạn 2 (tùy chọn): unfreeze backbone 1 phần để fine-tune\n",
    "    # Việc này tăng chất lượng nhưng chậm hơn trên CPU – bật nếu bạn có thời gian\n",
    "    # và đã thấy loss/acc ổn định ở stage 1.\n",
    "\n",
    "if UNFREEZE:\n",
    "    print(\"Unfreezing backbone for fine-tuning...\")\n",
    "    \n",
    "    \n",
    "    # model.get_layer(\"efficientnetb4\").trainable = True\n",
    "    for l in model.layers:\n",
    "    # freeze mặc định\n",
    "        l.trainable = False\n",
    "    # mở khoá các block cuối và giữ head trainable\n",
    "        if l.name.startswith((\"block6\", \"block7\")) or isinstance(l, tf.keras.layers.Dense):\n",
    "            l.trainable = True\n",
    "        if isinstance(l, tf.keras.layers.BatchNormalization):\n",
    "            l.trainable = False  # vẫn giữ BN đóng băng\n",
    "\n",
    "\n",
    "        # re-compile với LR nhỏ hơn\n",
    "    try:\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "    except Exception:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "\n",
    "    callbacks_ft = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\"models/effb4_dualhead_stage2.keras\",\n",
    "                                               monitor=\"val_loss\", save_best_only=True)\n",
    "        ]\n",
    "    \n",
    "    losses = {\n",
    "        \"softmax\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"ordinal\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    }\n",
    "    loss_weights = {\"softmax\": LOSS_W_SOFTMAX, \"ordinal\": LOSS_W_ORDINAL}\n",
    "\n",
    "    metrics = {\n",
    "        \"softmax\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "        \"ordinal\": [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)],\n",
    "    }\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                  loss_weights=loss_weights, metrics=metrics)\n",
    "    print(\"\\n=== Stage 2: Fine-tuning (unfrozen) ===\")\n",
    "    history2 = model.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_val,\n",
    "            epochs=max(5, EPOCHS//2),\n",
    "            callbacks=callbacks_ft,\n",
    "            verbose=1\n",
    "        )\n",
    "print(\"\\nDone (xây dựng & compile xong; train cơ bản đã chạy).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc94b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipynb-py-convert structure_model_v2.ipynb plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a1d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
