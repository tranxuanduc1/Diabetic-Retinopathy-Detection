{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6061886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 10:40:31.721166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-13 10:40:31.842788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755096031.887423    6357 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755096031.900435    6357 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755096032.002448    6357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096032.002471    6357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096032.002472    6357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755096032.002474    6357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-13 10:40:32.016029: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adab0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d692a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, gc\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "# Bật memory growth (rất quan trọng)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== CONFIG ==================\n",
    "TRAIN_DIR = \"eyepacs_2015/train_augmented_preprocess\"\n",
    "VAL_DIR   = \"eyepacs_2015/val_preprocess\"\n",
    "\n",
    "IMAGE_SIZE = 448       # 448 hoặc 512 cho CPU; 600 sẽ rất chậm trên CPU\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "FREEZE_BACKBONE = True   # freeze giai đoạn đầu cho CPU\n",
    "DROP_RATE = 0.4          # dropout trong head\n",
    "DENSE_UNITS = 1024\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LOSS_W_SOFTMAX = 1.0\n",
    "LOSS_W_ORDINAL = 0.5\n",
    "\n",
    "EPOCHS = 20              # ví dụ (bạn tăng sau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3674e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4b0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Ordinal utils ==========\n",
    "def ordinal_encode_tf(y_int):\n",
    "    \"\"\"y_int: (B,) int32 0..4 -> (B,4) float32: [y>=1, y>=2, y>=3, y>=4]\"\"\"\n",
    "    y_int = tf.cast(y_int, tf.int32)\n",
    "    thresholds = tf.constant([1, 2, 3, 4], dtype=tf.int32)  # (4,)\n",
    "    y_exp = tf.expand_dims(y_int, axis=-1)                  # (B,1)\n",
    "    return tf.cast(y_exp >= thresholds, tf.float32)         # (B,4)\n",
    "\n",
    "def map_preprocess(image, label):\n",
    "    # image_dataset_from_directory trả image uint8 [0..255]; EfficientNet preprocess sẽ scale\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = preprocess_input(image)  # -> [0..1] cho EfficientNet\n",
    "    return image, label\n",
    "\n",
    "def map_dual_targets(image, y_int):\n",
    "    # tạo 2 nhãn: softmax (int) và ordinal (4-dim)\n",
    "    return image, {\n",
    "        \"softmax\": tf.cast(y_int, tf.int32),\n",
    "        \"ordinal\": ordinal_encode_tf(y_int)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8fab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Dataset loaders (không cache vào RAM) ==========\n",
    "def make_ds(data_dir, subset=\"train\"):\n",
    "    ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=[\"0\",\"1\",\"2\",\"3\",\"4\"],   # cố định thứ tự nhãn\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        shuffle=(subset==\"train\"),\n",
    "        seed=SEED\n",
    "    )\n",
    "    ds = ds.map(map_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(map_dual_targets, num_parallel_calls=AUTOTUNE)\n",
    "    # Không dùng .cache() để tiết kiệm RAM; chỉ prefetch\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99119d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sca_block(x, ratio=8, name=\"sca\"):\n",
    "    \"\"\"Simple Channel Attention: GAP -> 1x1 Conv (reduce) -> 1x1 Conv (gate sigmoid) -> multiply.\"\"\"\n",
    "    ch = int(x.shape[-1])\n",
    "    mid = max(ch // ratio, 1)\n",
    "\n",
    "    gap = layers.GlobalAveragePooling2D(keepdims=True, name=f\"{name}_gap\")(x)\n",
    "    red = layers.Conv2D(mid, 1, padding=\"same\", activation=\"relu\",\n",
    "                        use_bias=True, name=f\"{name}_reduce\")(gap)\n",
    "    gate = layers.Conv2D(ch, 1, padding=\"same\", activation=\"sigmoid\",\n",
    "                         use_bias=True, name=f\"{name}_gate\")(red)\n",
    "    out = layers.Multiply(name=f\"{name}_mul\")([x, gate])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5fdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model builder ==========\n",
    "def build_model(img_size=IMAGE_SIZE, freeze_backbone=FREEZE_BACKBONE):\n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    # Backbone EfficientNet-B4 (ImageNet)\n",
    "    base = EfficientNetB4(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    base.trainable = not freeze_backbone\n",
    "\n",
    "    x = base.output\n",
    "    # CBAM ở feature map cuối (nhẹ)\n",
    "    x = sca_block(x, ratio=8, name=\"sca\")\n",
    "\n",
    "    # Global pooling + head chung\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE)(x)\n",
    "    x = layers.Dense(DENSE_UNITS, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE * 0.75)(x)\n",
    "\n",
    "    # Head A: Softmax 5 lớp\n",
    "    out_soft = layers.Dense(5, activation=\"softmax\", name=\"softmax\")(x)\n",
    "    # Head B: Ordinal (≥1..4), sigmoid\n",
    "    out_ord  = layers.Dense(4, activation=\"sigmoid\", name=\"ordinal\")(x)\n",
    "\n",
    "    model = models.Model(inputs, [out_soft, out_ord], name=\"EffB4_CBAM_DualHead\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e5b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Compile ==========\n",
    "def compile_model(model,\n",
    "                  lr=LR,\n",
    "                  wd=WEIGHT_DECAY,\n",
    "                  loss_w_softmax=LOSS_W_SOFTMAX,\n",
    "                  loss_w_ordinal=LOSS_W_ORDINAL):\n",
    "    try:\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "    except Exception:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    losses = {\n",
    "        \"softmax\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"ordinal\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    }\n",
    "    loss_weights = {\"softmax\": loss_w_softmax, \"ordinal\": loss_w_ordinal}\n",
    "\n",
    "    metrics = {\n",
    "        \"softmax\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "        \"ordinal\": [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)],\n",
    "    }\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                  loss_weights=loss_weights, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81327a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Found 105218 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754997129.170722    3415 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2281 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 5 classes.\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# ================== MAIN ==================\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "ds_train = make_ds(TRAIN_DIR, subset=\"train\")\n",
    "ds_val   = make_ds(VAL_DIR, subset=\"val\")\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model = compile_model(model)\n",
    "\n",
    "# model.summary(line_length=120)\n",
    "\n",
    "    # Giai đoạn 1: (khuyên dùng cho CPU) train head với backbone freeze\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"models/effb4_eyespacs2015_dualhead_stage1.keras\",\n",
    "                                           monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8970692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1: Train head (backbone frozen) ===\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754979930.270809    3276 service.cc:152] XLA service 0x7f58fc002f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754979930.270833    3276 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-08-12 02:25:31.040088: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1754979933.814394    3276 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-12 02:25:39.112618: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-12 02:25:39.260733: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/13153\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m130:12:45\u001b[0m 36s/step - loss: 2.4414 - ordinal_auc: 0.4762 - ordinal_loss: 0.9753 - softmax_acc: 0.2500 - softmax_loss: 1.9538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754979954.897841    3276 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13152/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.6470 - ordinal_auc: 0.8090 - ordinal_loss: 0.4697 - softmax_acc: 0.4587 - softmax_loss: 1.4122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 02:48:38.740525: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-12 02:48:38.869947: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1433s\u001b[0m 106ms/step - loss: 1.6470 - ordinal_auc: 0.8090 - ordinal_loss: 0.4697 - softmax_acc: 0.4587 - softmax_loss: 1.4122 - val_loss: 1.6402 - val_ordinal_auc: 0.8805 - val_ordinal_loss: 0.4600 - val_softmax_acc: 0.4130 - val_softmax_loss: 1.4103 - learning_rate: 3.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1378s\u001b[0m 105ms/step - loss: 1.2396 - ordinal_auc: 0.8929 - ordinal_loss: 0.3392 - softmax_acc: 0.5512 - softmax_loss: 1.0700 - val_loss: 1.6513 - val_ordinal_auc: 0.8903 - val_ordinal_loss: 0.4631 - val_softmax_acc: 0.4250 - val_softmax_loss: 1.4198 - learning_rate: 3.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 104ms/step - loss: 1.1733 - ordinal_auc: 0.9054 - ordinal_loss: 0.3193 - softmax_acc: 0.5750 - softmax_loss: 1.0136 - val_loss: 1.6998 - val_ordinal_auc: 0.8921 - val_ordinal_loss: 0.4918 - val_softmax_acc: 0.3960 - val_softmax_loss: 1.4539 - learning_rate: 3.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1372s\u001b[0m 104ms/step - loss: 1.1307 - ordinal_auc: 0.9114 - ordinal_loss: 0.3091 - softmax_acc: 0.5914 - softmax_loss: 0.9762 - val_loss: 1.5012 - val_ordinal_auc: 0.8918 - val_ordinal_loss: 0.4190 - val_softmax_acc: 0.4780 - val_softmax_loss: 1.2917 - learning_rate: 3.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1369s\u001b[0m 104ms/step - loss: 1.0965 - ordinal_auc: 0.9168 - ordinal_loss: 0.3001 - softmax_acc: 0.6056 - softmax_loss: 0.9464 - val_loss: 2.0898 - val_ordinal_auc: 0.8791 - val_ordinal_loss: 0.6330 - val_softmax_acc: 0.3740 - val_softmax_loss: 1.7733 - learning_rate: 3.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 104ms/step - loss: 1.0767 - ordinal_auc: 0.9198 - ordinal_loss: 0.2948 - softmax_acc: 0.6160 - softmax_loss: 0.9293 - val_loss: 1.5908 - val_ordinal_auc: 0.8811 - val_ordinal_loss: 0.4450 - val_softmax_acc: 0.4350 - val_softmax_loss: 1.3683 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 104ms/step - loss: 1.0589 - ordinal_auc: 0.9225 - ordinal_loss: 0.2907 - softmax_acc: 0.6204 - softmax_loss: 0.9135 - val_loss: 1.7462 - val_ordinal_auc: 0.8771 - val_ordinal_loss: 0.4959 - val_softmax_acc: 0.4190 - val_softmax_loss: 1.4982 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 104ms/step - loss: 1.0132 - ordinal_auc: 0.9282 - ordinal_loss: 0.2795 - softmax_acc: 0.6382 - softmax_loss: 0.8735 - val_loss: 1.6952 - val_ordinal_auc: 0.8700 - val_ordinal_loss: 0.4546 - val_softmax_acc: 0.4480 - val_softmax_loss: 1.4680 - learning_rate: 1.5000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1369s\u001b[0m 104ms/step - loss: 0.9901 - ordinal_auc: 0.9316 - ordinal_loss: 0.2730 - softmax_acc: 0.6451 - softmax_loss: 0.8536 - val_loss: 1.8502 - val_ordinal_auc: 0.8876 - val_ordinal_loss: 0.5240 - val_softmax_acc: 0.4120 - val_softmax_loss: 1.5882 - learning_rate: 1.5000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Stage 1: Train head (backbone frozen) ===\")\n",
    "history1 = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fdbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755096060.990415    6357 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2281 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "  # bật True nếu muốn fine-tune tiếp   \n",
    "UNFREEZE=True\n",
    "model_stage2=tf.keras.models.load_model('models/effb4_eyespacs2015_dualhead_stage1.keras',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aae7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem_bn\n",
      "block1a_bn\n",
      "block1a_project_bn\n",
      "block1b_bn\n",
      "block1b_project_bn\n",
      "block2a_expand_bn\n",
      "block2a_bn\n",
      "block2a_project_bn\n",
      "block2b_expand_bn\n",
      "block2b_bn\n",
      "block2b_project_bn\n",
      "block2c_expand_bn\n",
      "block2c_bn\n",
      "block2c_project_bn\n",
      "block2d_expand_bn\n",
      "block2d_bn\n",
      "block2d_project_bn\n",
      "block3a_expand_bn\n",
      "block3a_bn\n",
      "block3a_project_bn\n",
      "block3b_expand_bn\n",
      "block3b_bn\n",
      "block3b_project_bn\n",
      "block3c_expand_bn\n",
      "block3c_bn\n",
      "block3c_project_bn\n",
      "block3d_expand_bn\n",
      "block3d_bn\n",
      "block3d_project_bn\n",
      "block4a_expand_bn\n",
      "block4a_bn\n",
      "block4a_project_bn\n",
      "block4b_expand_bn\n",
      "block4b_bn\n",
      "block4b_project_bn\n",
      "block4c_expand_bn\n",
      "block4c_bn\n",
      "block4c_project_bn\n",
      "block4d_expand_bn\n",
      "block4d_bn\n",
      "block4d_project_bn\n",
      "block4e_expand_bn\n",
      "block4e_bn\n",
      "block4e_project_bn\n",
      "block4f_expand_bn\n",
      "block4f_bn\n",
      "block4f_project_bn\n",
      "block5a_expand_bn\n",
      "block5a_bn\n",
      "block5a_project_bn\n",
      "block5b_expand_bn\n",
      "block5b_bn\n",
      "block5b_project_bn\n",
      "block5c_expand_bn\n",
      "block5c_bn\n",
      "block5c_project_bn\n",
      "block5d_expand_bn\n",
      "block5d_bn\n",
      "block5d_project_bn\n",
      "block5e_expand_bn\n",
      "block5e_bn\n",
      "block5e_project_bn\n",
      "block5f_expand_bn\n",
      "block5f_bn\n",
      "block5f_project_bn\n",
      "block6a_expand_bn\n",
      "block6a_bn\n",
      "block6a_project_bn\n",
      "block6b_expand_bn\n",
      "block6b_bn\n",
      "block6b_project_bn\n",
      "block6c_expand_bn\n",
      "block6c_bn\n",
      "block6c_project_bn\n",
      "block6d_expand_bn\n",
      "block6d_bn\n",
      "block6d_project_bn\n",
      "block6e_expand_bn\n",
      "block6e_bn\n",
      "block6e_project_bn\n",
      "block6f_expand_bn\n",
      "block6f_bn\n",
      "block6f_project_bn\n",
      "block6g_expand_bn\n",
      "block6g_bn\n",
      "block6g_project_bn\n",
      "block6h_expand_bn\n",
      "block6h_bn\n",
      "block6h_project_bn\n",
      "block7a_expand_bn\n",
      "block7a_bn\n",
      "block7a_project_bn\n",
      "block7b_expand_bn\n",
      "block7b_bn\n",
      "block7b_project_bn\n",
      "top_bn\n",
      "batch_normalization\n",
      "batch_normalization_1\n"
     ]
    }
   ],
   "source": [
    "for layer in model_stage2.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167b4bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfreezing backbone for fine-tuning...\n",
      "\n",
      "=== Stage 2: Fine-tuning (unfrozen) ===\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754997156.555290    6282 service.cc:152] XLA service 0x75ca70015860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754997156.555314    6282 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-08-12 07:12:37.459913: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1754997160.749902    6282 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-12 07:12:46.533189: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-12 07:12:46.681363: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/13153\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m171:25:25\u001b[0m 47s/step - loss: 1.1071 - ordinal_auc: 0.5833 - ordinal_loss: 0.3162 - softmax_acc: 0.5000 - softmax_loss: 0.9490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754997188.602608    6282 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13152/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.9832 - ordinal_auc: 0.9370 - ordinal_loss: 0.2578 - softmax_acc: 0.6451 - softmax_loss: 0.8542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 07:45:09.161195: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-12 07:45:09.290700: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2006s\u001b[0m 149ms/step - loss: 0.9831 - ordinal_auc: 0.9370 - ordinal_loss: 0.2578 - softmax_acc: 0.6451 - softmax_loss: 0.8542 - val_loss: 2.1499 - val_ordinal_auc: 0.8847 - val_ordinal_loss: 0.6365 - val_softmax_acc: 0.4450 - val_softmax_loss: 1.8316 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1943s\u001b[0m 148ms/step - loss: 0.5621 - ordinal_auc: 0.9785 - ordinal_loss: 0.1440 - softmax_acc: 0.8043 - softmax_loss: 0.4901 - val_loss: 2.9139 - val_ordinal_auc: 0.8639 - val_ordinal_loss: 0.8440 - val_softmax_acc: 0.4460 - val_softmax_loss: 2.4919 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1921s\u001b[0m 146ms/step - loss: 0.3694 - ordinal_auc: 0.9889 - ordinal_loss: 0.0959 - softmax_acc: 0.8778 - softmax_loss: 0.3214 - val_loss: 2.5758 - val_ordinal_auc: 0.8852 - val_ordinal_loss: 0.7058 - val_softmax_acc: 0.5010 - val_softmax_loss: 2.2229 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1920s\u001b[0m 146ms/step - loss: 0.2631 - ordinal_auc: 0.9937 - ordinal_loss: 0.0697 - softmax_acc: 0.9169 - softmax_loss: 0.2282 - val_loss: 2.6037 - val_ordinal_auc: 0.8941 - val_ordinal_loss: 0.6680 - val_softmax_acc: 0.5150 - val_softmax_loss: 2.2698 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1918s\u001b[0m 146ms/step - loss: 0.1413 - ordinal_auc: 0.9977 - ordinal_loss: 0.0391 - softmax_acc: 0.9566 - softmax_loss: 0.1218 - val_loss: 4.0763 - val_ordinal_auc: 0.8558 - val_ordinal_loss: 1.1145 - val_softmax_acc: 0.4690 - val_softmax_loss: 3.5190 - learning_rate: 5.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m13153/13153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1927s\u001b[0m 147ms/step - loss: 0.0900 - ordinal_auc: 0.9989 - ordinal_loss: 0.0250 - softmax_acc: 0.9730 - softmax_loss: 0.0774 - val_loss: 4.0855 - val_ordinal_auc: 0.8546 - val_ordinal_loss: 1.0930 - val_softmax_acc: 0.4760 - val_softmax_loss: 3.5390 - learning_rate: 5.0000e-05\n",
      "\n",
      "Done (xây dựng & compile xong; train cơ bản đã chạy).\n"
     ]
    }
   ],
   "source": [
    " # Giai đoạn 2 (tùy chọn): unfreeze backbone 1 phần để fine-tune\n",
    "    # Việc này tăng chất lượng nhưng chậm hơn trên CPU – bật nếu bạn có thời gian\n",
    "    # và đã thấy loss/acc ổn định ở stage 1.\n",
    "\n",
    "if UNFREEZE:\n",
    "    print(\"Unfreezing backbone for fine-tuning...\")\n",
    "    \n",
    "    \n",
    "    # model.get_layer(\"efficientnetb4\").trainable = True\n",
    "    for l in model_stage2.layers:\n",
    "    # freeze mặc định\n",
    "        l.trainable = False\n",
    "    # mở khoá các block cuối và giữ head trainable\n",
    "        if l.name.startswith((\"block6\", \"block7\")) or isinstance(l, tf.keras.layers.Dense):\n",
    "            l.trainable = True\n",
    "        if isinstance(l, tf.keras.layers.BatchNormalization):\n",
    "            l.trainable = False  # vẫn giữ BN đóng băng\n",
    "\n",
    "\n",
    "        # re-compile với LR nhỏ hơn\n",
    "    try:\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=WEIGHT_DECAY)\n",
    "    except Exception:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "\n",
    "    callbacks_ft = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\"models/effb4_eyespacs2_dualhead_stage2.keras\",\n",
    "                                               monitor=\"val_loss\", save_best_only=True)\n",
    "        ]\n",
    "    \n",
    "    losses = {\n",
    "        \"softmax\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"ordinal\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    }\n",
    "    loss_weights = {\"softmax\": LOSS_W_SOFTMAX, \"ordinal\": LOSS_W_ORDINAL}\n",
    "\n",
    "    metrics = {\n",
    "        \"softmax\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "        \"ordinal\": [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)],\n",
    "    }\n",
    "\n",
    "    model_stage2.compile(optimizer=optimizer, loss=losses,\n",
    "                  loss_weights=loss_weights, metrics=metrics)\n",
    "    print(\"\\n=== Stage 2: Fine-tuning (unfrozen) ===\")\n",
    "    history2 = model_stage2.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_val,\n",
    "            epochs=20,\n",
    "            callbacks=callbacks_ft,\n",
    "            verbose=1\n",
    "        )\n",
    "print(\"\\nDone (xây dựng & compile xong; train cơ bản đã chạy).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc94b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipynb-py-convert structure_model_v2.ipynb plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a1d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
