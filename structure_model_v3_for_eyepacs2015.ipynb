{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6061886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 22:22:06.059739: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-14 22:22:06.070499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755224526.083766    5762 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755224526.087682    5762 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755224526.097279    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755224526.097300    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755224526.097301    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755224526.097303    5762 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-14 22:22:06.100914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adab0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d692a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, gc\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "# Bật memory growth (rất quan trọng)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== CONFIG ==================\n",
    "TRAIN_DIR = \"eyepacs_2015/train_preprocess\"\n",
    "VAL_DIR   = \"eyepacs_2015/val_preprocess\"\n",
    "\n",
    "IMAGE_SIZE = 448       # 448 hoặc 512 cho CPU; 600 sẽ rất chậm trên CPU\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "FREEZE_BACKBONE = True   # freeze giai đoạn đầu cho CPU\n",
    "DROP_RATE = 0.4          # dropout trong head\n",
    "DENSE_UNITS = 1024\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LOSS_W_SOFTMAX = 1.0\n",
    "LOSS_W_ORDINAL = 0.5\n",
    "\n",
    "EPOCHS = 15              # ví dụ (bạn tăng sau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3674e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4b0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Ordinal utils ==========\n",
    "def ordinal_encode_tf(y_int):\n",
    "    \"\"\"y_int: (B,) int32 0..4 -> (B,4) float32: [y>=1, y>=2, y>=3, y>=4]\"\"\"\n",
    "    y_int = tf.cast(y_int, tf.int32)\n",
    "    thresholds = tf.constant([1, 2, 3, 4], dtype=tf.int32)  # (4,)\n",
    "    y_exp = tf.expand_dims(y_int, axis=-1)                  # (B,1)\n",
    "    return tf.cast(y_exp >= thresholds, tf.float32)         # (B,4)\n",
    "\n",
    "def map_preprocess(image, label):\n",
    "    # image_dataset_from_directory trả image uint8 [0..255]; EfficientNet preprocess sẽ scale\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = preprocess_input(image)  # -> [0..1] cho EfficientNet\n",
    "    return image, label\n",
    "\n",
    "def map_dual_targets(image, y_int):\n",
    "    # tạo 2 nhãn: softmax (int) và ordinal (4-dim)\n",
    "    return image, {\n",
    "        \"softmax\": tf.cast(y_int, tf.int32),\n",
    "        \"ordinal\": ordinal_encode_tf(y_int)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8fab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Dataset loaders (không cache vào RAM) ==========\n",
    "def make_ds(data_dir, subset=\"train\"):\n",
    "    ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=[\"0\",\"1\",\"2\",\"3\",\"4\"],   # cố định thứ tự nhãn\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        shuffle=(subset==\"train\"),\n",
    "        seed=SEED\n",
    "    )\n",
    "    ds = ds.map(map_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(map_dual_targets, num_parallel_calls=AUTOTUNE)\n",
    "    # Không dùng .cache() để tiết kiệm RAM; chỉ prefetch\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99119d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sca_block(x, ratio=8, name=\"sca\"):\n",
    "    \"\"\"Simple Channel Attention: GAP -> 1x1 Conv (reduce) -> 1x1 Conv (gate sigmoid) -> multiply.\"\"\"\n",
    "    ch = int(x.shape[-1])\n",
    "    mid = max(ch // ratio, 1)\n",
    "\n",
    "    gap = layers.GlobalAveragePooling2D(keepdims=True, name=f\"{name}_gap\")(x)\n",
    "    red = layers.Conv2D(mid, 1, padding=\"same\", activation=\"relu\",\n",
    "                        use_bias=True, name=f\"{name}_reduce\")(gap)\n",
    "    gate = layers.Conv2D(ch, 1, padding=\"same\", activation=\"sigmoid\",\n",
    "                         use_bias=True, name=f\"{name}_gate\")(red)\n",
    "    out = layers.Multiply(name=f\"{name}_mul\")([x, gate])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5fdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model builder ==========\n",
    "def build_model(img_size=IMAGE_SIZE, freeze_backbone=FREEZE_BACKBONE):\n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    # Backbone EfficientNet-B4 (ImageNet)\n",
    "    base = EfficientNetB4(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    base.trainable = not freeze_backbone\n",
    "\n",
    "    x = base.output\n",
    "    # CBAM ở feature map cuối (nhẹ)\n",
    "    x = sca_block(x, ratio=8, name=\"sca\")\n",
    "\n",
    "    # Global pooling + head chung\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE)(x)\n",
    "    x = layers.Dense(DENSE_UNITS, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE * 0.75)(x)\n",
    "\n",
    "    # Head A: Softmax 5 lớp\n",
    "    out_soft = layers.Dense(5, activation=\"softmax\", name=\"softmax\")(x)\n",
    "    # Head B: Ordinal (≥1..4), sigmoid\n",
    "    out_ord  = layers.Dense(4, activation=\"sigmoid\", name=\"ordinal\")(x)\n",
    "\n",
    "    model = models.Model(inputs, [out_soft, out_ord], name=\"EffB4_CBAM_DualHead\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e5b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Compile ==========\n",
    "def compile_model(model,\n",
    "                  lr=LR,\n",
    "                  wd=WEIGHT_DECAY,\n",
    "                  loss_w_softmax=LOSS_W_SOFTMAX,\n",
    "                  loss_w_ordinal=LOSS_W_ORDINAL):\n",
    "    try:\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "    except Exception:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    losses = {\n",
    "        \"softmax\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"ordinal\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    }\n",
    "    loss_weights = {\"softmax\": loss_w_softmax, \"ordinal\": loss_w_ordinal}\n",
    "\n",
    "    metrics = {\n",
    "        \"softmax\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "        \"ordinal\": [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)],\n",
    "    }\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                  loss_weights=loss_weights, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81327a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Found 105145 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755224551.383759    5762 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1220 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3511 files belonging to 5 classes.\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# ================== MAIN ==================\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "ds_train = make_ds(TRAIN_DIR, subset=\"train\")\n",
    "ds_val   = make_ds(VAL_DIR, subset=\"val\")\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model = compile_model(model)\n",
    "\n",
    "# model.summary(line_length=120)\n",
    "\n",
    "    # Giai đoạn 1: (khuyên dùng cho CPU) train head với backbone freeze\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"models/effb4_eyespacs2015_dualhead_v3_stage1.keras\",\n",
    "                                           monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a29a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Hàm mở block và train từng stage =====\n",
    "def unfreeze_blocks_by_prefix(model, prefixes):\n",
    "    \"\"\"Mở các block theo prefix như 'block6', 'block7'\"\"\"\n",
    "    for layer in model.layers:\n",
    "        if any(layer.name.startswith(pref) for pref in prefixes):\n",
    "            layer.trainable = True\n",
    "        elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "\n",
    "def run_finetune_stage(model, stage_idx, prefixes, lr, save_path):\n",
    "    print(f\"\\n=== Stage {stage_idx}: Unfreeze {prefixes} ===\")\n",
    "    unfreeze_blocks_by_prefix(model, prefixes)\n",
    "\n",
    "    try:\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=WEIGHT_DECAY)\n",
    "    except Exception:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    losses = {\n",
    "        \"softmax\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"ordinal\": tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    }\n",
    "    loss_weights = {\"softmax\": LOSS_W_SOFTMAX, \"ordinal\": LOSS_W_ORDINAL}\n",
    "    metrics = {\n",
    "        \"softmax\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "        \"ordinal\": [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)],\n",
    "    }\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                  loss_weights=loss_weights, metrics=metrics)\n",
    "\n",
    "    callbacks_ft = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(save_path, monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks_ft,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8970692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1: Train head (backbone frozen) ===\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755187141.203209   13601 service.cc:152] XLA service 0x710da8001f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755187141.203289   13601 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-08-14 11:59:02.223169: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755187145.570822   13601 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-14 11:59:11.982511: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 11:59:12.131942: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/13144\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m160:28:30\u001b[0m 44s/step - loss: 3.3745 - ordinal_auc: 0.5244 - ordinal_loss: 1.0606 - softmax_acc: 0.2500 - softmax_loss: 2.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755187171.205533   13601 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13143/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.5935 - ordinal_auc: 0.8424 - ordinal_loss: 0.4513 - softmax_acc: 0.4884 - softmax_loss: 1.3679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 12:22:17.561156: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 12:22:17.680085: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.5935 - ordinal_auc: 0.8424 - ordinal_loss: 0.4513 - softmax_acc: 0.4884 - softmax_loss: 1.3679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 12:23:26.164668: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 12:23:26.311810: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1490s\u001b[0m 110ms/step - loss: 1.5935 - ordinal_auc: 0.8424 - ordinal_loss: 0.4513 - softmax_acc: 0.4884 - softmax_loss: 1.3679 - val_loss: 0.9548 - val_ordinal_auc: 0.8711 - val_ordinal_loss: 0.2744 - val_softmax_acc: 0.7508 - val_softmax_loss: 0.8178 - learning_rate: 3.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1399s\u001b[0m 106ms/step - loss: 1.1862 - ordinal_auc: 0.9103 - ordinal_loss: 0.3281 - softmax_acc: 0.5791 - softmax_loss: 1.0222 - val_loss: 0.8723 - val_ordinal_auc: 0.8754 - val_ordinal_loss: 0.2559 - val_softmax_acc: 0.7542 - val_softmax_loss: 0.7445 - learning_rate: 3.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1396s\u001b[0m 106ms/step - loss: 1.1182 - ordinal_auc: 0.9208 - ordinal_loss: 0.3087 - softmax_acc: 0.6060 - softmax_loss: 0.9638 - val_loss: 0.8510 - val_ordinal_auc: 0.8695 - val_ordinal_loss: 0.2436 - val_softmax_acc: 0.7545 - val_softmax_loss: 0.7294 - learning_rate: 3.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1397s\u001b[0m 106ms/step - loss: 1.0720 - ordinal_auc: 0.9274 - ordinal_loss: 0.2959 - softmax_acc: 0.6232 - softmax_loss: 0.9241 - val_loss: 0.8471 - val_ordinal_auc: 0.8651 - val_ordinal_loss: 0.2493 - val_softmax_acc: 0.7608 - val_softmax_loss: 0.7228 - learning_rate: 3.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1397s\u001b[0m 106ms/step - loss: 1.0429 - ordinal_auc: 0.9307 - ordinal_loss: 0.2893 - softmax_acc: 0.6370 - softmax_loss: 0.8982 - val_loss: 0.8342 - val_ordinal_auc: 0.8698 - val_ordinal_loss: 0.2457 - val_softmax_acc: 0.7716 - val_softmax_loss: 0.7117 - learning_rate: 3.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1396s\u001b[0m 106ms/step - loss: 1.0266 - ordinal_auc: 0.9327 - ordinal_loss: 0.2856 - softmax_acc: 0.6444 - softmax_loss: 0.8839 - val_loss: 0.8853 - val_ordinal_auc: 0.8618 - val_ordinal_loss: 0.2646 - val_softmax_acc: 0.7616 - val_softmax_loss: 0.7535 - learning_rate: 3.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1396s\u001b[0m 106ms/step - loss: 0.9981 - ordinal_auc: 0.9363 - ordinal_loss: 0.2777 - softmax_acc: 0.6533 - softmax_loss: 0.8593 - val_loss: 0.8603 - val_ordinal_auc: 0.8672 - val_ordinal_loss: 0.2500 - val_softmax_acc: 0.7664 - val_softmax_loss: 0.7356 - learning_rate: 3.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1398s\u001b[0m 106ms/step - loss: 0.9795 - ordinal_auc: 0.9386 - ordinal_loss: 0.2728 - softmax_acc: 0.6601 - softmax_loss: 0.8432 - val_loss: 0.8158 - val_ordinal_auc: 0.8682 - val_ordinal_loss: 0.2401 - val_softmax_acc: 0.7690 - val_softmax_loss: 0.6963 - learning_rate: 3.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1397s\u001b[0m 106ms/step - loss: 0.9675 - ordinal_auc: 0.9399 - ordinal_loss: 0.2699 - softmax_acc: 0.6643 - softmax_loss: 0.8325 - val_loss: 0.8488 - val_ordinal_auc: 0.8651 - val_ordinal_loss: 0.2470 - val_softmax_acc: 0.7625 - val_softmax_loss: 0.7256 - learning_rate: 3.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1396s\u001b[0m 106ms/step - loss: 0.9520 - ordinal_auc: 0.9419 - ordinal_loss: 0.2655 - softmax_acc: 0.6685 - softmax_loss: 0.8193 - val_loss: 0.8343 - val_ordinal_auc: 0.8617 - val_ordinal_loss: 0.2432 - val_softmax_acc: 0.7664 - val_softmax_loss: 0.7133 - learning_rate: 3.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1395s\u001b[0m 106ms/step - loss: 0.9400 - ordinal_auc: 0.9430 - ordinal_loss: 0.2628 - softmax_acc: 0.6736 - softmax_loss: 0.8086 - val_loss: 0.8478 - val_ordinal_auc: 0.8709 - val_ordinal_loss: 0.2479 - val_softmax_acc: 0.7639 - val_softmax_loss: 0.7243 - learning_rate: 3.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1394s\u001b[0m 106ms/step - loss: 0.8973 - ordinal_auc: 0.9476 - ordinal_loss: 0.2517 - softmax_acc: 0.6880 - softmax_loss: 0.7715 - val_loss: 0.8344 - val_ordinal_auc: 0.8703 - val_ordinal_loss: 0.2442 - val_softmax_acc: 0.7682 - val_softmax_loss: 0.7127 - learning_rate: 1.5000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1393s\u001b[0m 106ms/step - loss: 0.8787 - ordinal_auc: 0.9494 - ordinal_loss: 0.2473 - softmax_acc: 0.6960 - softmax_loss: 0.7551 - val_loss: 0.8199 - val_ordinal_auc: 0.8667 - val_ordinal_loss: 0.2408 - val_softmax_acc: 0.7704 - val_softmax_loss: 0.7001 - learning_rate: 1.5000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Stage 1: Train head (backbone frozen) ===\")\n",
    "history1 = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc94b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/duc/Documents/DoAn/myvenv/bin/ipynb-py-convert\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/duc/Documents/DoAn/myvenv/lib/python3.10/site-packages/ipynb_py_convert/__main__.py\", line 105, in main\n",
      "    convert(in_file=argv[1], out_file=argv[2])\n",
      "  File \"/home/duc/Documents/DoAn/myvenv/lib/python3.10/site-packages/ipynb_py_convert/__main__.py\", line 95, in convert\n",
      "    raise(Exception('Extensions must be .ipynb and .py or vice versa'))\n",
      "Exception: Extensions must be .ipynb and .py or vice versa\n"
     ]
    }
   ],
   "source": [
    "!ipynb-py-convert structure_model_v3 _for_eyepacs2015.ipynb plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09cf154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 checkpoint found: models/effb4_eyespacs2015_dualhead_v3_stage1.keras, loading...\n",
      "\n",
      "=== Stage 2: Unfreeze ['block6', 'block7'] ===\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755224831.706435    7572 service.cc:152] XLA service 0x753660005950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755224831.706459    7572 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-08-14 22:27:12.844631: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755224836.955992    7572 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-14 22:27:23.817219: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 22:27:23.965902: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 22:27:24.657875: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.657911: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.657943: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.657956: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.657971: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.657986: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.657999: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.686264: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.686298: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-14 22:27:24.686312: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 273.26MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/13144\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m214:14:23\u001b[0m 59s/step - loss: 7.6898 - ordinal_auc: 0.4730 - ordinal_loss: 2.1253 - softmax_acc: 0.1250 - softmax_loss: 6.6272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755224870.261254    7572 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13143/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.0748 - ordinal_auc: 0.9314 - ordinal_loss: 0.2847 - softmax_acc: 0.6286 - softmax_loss: 0.9324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 23:02:13.749052: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 23:02:13.868914: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.0747 - ordinal_auc: 0.9314 - ordinal_loss: 0.2847 - softmax_acc: 0.6286 - softmax_loss: 0.9324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 23:03:28.185241: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-14 23:03:28.331664: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2207s\u001b[0m 163ms/step - loss: 1.0747 - ordinal_auc: 0.9314 - ordinal_loss: 0.2847 - softmax_acc: 0.6286 - softmax_loss: 0.9324 - val_loss: 0.9545 - val_ordinal_auc: 0.8977 - val_ordinal_loss: 0.2502 - val_softmax_acc: 0.7112 - val_softmax_loss: 0.8297 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2172s\u001b[0m 165ms/step - loss: 0.5446 - ordinal_auc: 0.9809 - ordinal_loss: 0.1407 - softmax_acc: 0.8123 - softmax_loss: 0.4742 - val_loss: 1.2933 - val_ordinal_auc: 0.8710 - val_ordinal_loss: 0.3320 - val_softmax_acc: 0.6582 - val_softmax_loss: 1.1291 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m    1/13144\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51:11\u001b[0m 234ms/step - loss: 0.0230 - ordinal_auc: 1.0000 - ordinal_loss: 0.0100 - softmax_acc: 1.0000 - softmax_loss: 0.0180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 23:39:51.050160: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 33554816 bytes after encountering the first element of size 33554816 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2161s\u001b[0m 164ms/step - loss: 0.3645 - ordinal_auc: 0.9897 - ordinal_loss: 0.0945 - softmax_acc: 0.8794 - softmax_loss: 0.3172 - val_loss: 1.4303 - val_ordinal_auc: 0.8562 - val_ordinal_loss: 0.3625 - val_softmax_acc: 0.6477 - val_softmax_loss: 1.2498 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2084s\u001b[0m 159ms/step - loss: 0.2634 - ordinal_auc: 0.9939 - ordinal_loss: 0.0693 - softmax_acc: 0.9155 - softmax_loss: 0.2288 - val_loss: 1.2932 - val_ordinal_auc: 0.8674 - val_ordinal_loss: 0.3331 - val_softmax_acc: 0.6790 - val_softmax_loss: 1.1276 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m 6128/13144\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m17:56\u001b[0m 153ms/step - loss: 0.1702 - ordinal_auc: 0.9969 - ordinal_loss: 0.0458 - softmax_acc: 0.9467 - softmax_loss: 0.1474"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/effb4_dualhead_stage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mrun_finetune_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training pipeline completed ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m, in \u001b[0;36mrun_finetune_stage\u001b[0;34m(model, stage_idx, prefixes, lr, save_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mlosses,\n\u001b[1;32m     30\u001b[0m               loss_weights\u001b[38;5;241m=\u001b[39mloss_weights, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     32\u001b[0m callbacks_ft \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     34\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m     35\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(save_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m ]\n\u001b[0;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stage definitions: mở block từ 7 → 1\n",
    "stage_blocks = [\n",
    "    [\"block6\", \"block7\"],\n",
    "    [\"block4\", \"block5\", \"block6\", \"block7\"],\n",
    "    [\"block2\", \"block3\", \"block4\", \"block5\", \"block6\", \"block7\"],\n",
    "]\n",
    "stage_lrs = [1e-4, 5e-5, 3e-5]\n",
    "\n",
    "# Stage 1 checkpoint\n",
    "stage1_path = \"models/effb4_eyespacs2015_dualhead_v3_stage1.keras\"\n",
    "\n",
    "if os.path.exists(stage1_path):\n",
    "    print(f\"Stage 1 checkpoint found: {stage1_path}, loading...\")\n",
    "    model = tf.keras.models.load_model(stage1_path, compile=False)\n",
    "else:\n",
    "    print(\"\\n=== Stage 1: Train head (backbone frozen) ===\")\n",
    "    history1 = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=10,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "            tf.keras.callbacks.ModelCheckpoint(stage1_path, monitor=\"val_loss\", save_best_only=True)\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(stage1_path)\n",
    "\n",
    "# Loop qua stage 2–8\n",
    "for i, (blocks, lr) in enumerate(zip(stage_blocks, stage_lrs), start=2):\n",
    "    save_path = f\"models/effb4_eyespacs2015_dualhead_v3_stage{i}.keras\"\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Stage {i} checkpoint found: {save_path}, loading...\")\n",
    "        model = tf.keras.models.load_model(save_path, compile=False)\n",
    "        continue\n",
    "\n",
    "    model = tf.keras.models.load_model(f\"models/effb4_dualhead_stage{i-1}.keras\", compile=False)\n",
    "    run_finetune_stage(model, i, blocks, lr, save_path)\n",
    "\n",
    "print(\"\\n=== Training pipeline completed ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
