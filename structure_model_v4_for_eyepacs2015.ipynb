{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6061886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 23:30:48.548230: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-16 23:30:48.676256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755401448.721607   15535 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755401448.734904   15535 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755401448.835376   15535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755401448.835410   15535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755401448.835411   15535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755401448.835412   15535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-16 23:30:48.847573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adab0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d692a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, gc\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "# Bật memory growth (rất quan trọng)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== CONFIG ==================\n",
    "TRAIN_DIR = \"eyepacs_2015/train_preprocess_ben_graham\"\n",
    "VAL_DIR   = \"eyepacs_2015/val_preprocess_ben_graham\"\n",
    "\n",
    "IMAGE_SIZE = 448       # 448 hoặc 512 cho CPU; 600 sẽ rất chậm trên CPU\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "FREEZE_BACKBONE = True   # freeze giai đoạn đầu cho CPU\n",
    "DROP_RATE = 0.4          # dropout trong head\n",
    "DENSE_UNITS = 1024\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LOSS_W_SOFTMAX = 1.0\n",
    "LOSS_W_ORDINAL = 0.5\n",
    "\n",
    "EPOCHS = 15              # ví dụ (bạn tăng sau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3674e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4b0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Ordinal utils ==========\n",
    "def ordinal_encode_tf(y_int):\n",
    "    \"\"\"y_int: (B,) int32 0..4 -> (B,4) float32: [y>=1, y>=2, y>=3, y>=4]\"\"\"\n",
    "    y_int = tf.cast(y_int, tf.int32)\n",
    "    thresholds = tf.constant([1, 2, 3, 4], dtype=tf.int32)  # (4,)\n",
    "    y_exp = tf.expand_dims(y_int, axis=-1)                  # (B,1)\n",
    "    return tf.cast(y_exp >= thresholds, tf.float32)         # (B,4)\n",
    "\n",
    "def map_preprocess(image, label):\n",
    "    # image_dataset_from_directory trả image uint8 [0..255]; EfficientNet preprocess sẽ scale\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = preprocess_input(image)  # -> [0..1] cho EfficientNet\n",
    "    return image, ordinal_encode_tf(label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8fab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Dataset loaders (không cache vào RAM) ==========\n",
    "def make_ds(data_dir, subset=\"train\"):\n",
    "    ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=[\"0\",\"1\",\"2\",\"3\",\"4\"],   # cố định thứ tự nhãn\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        shuffle=(subset==\"train\"),\n",
    "        seed=SEED\n",
    "    )\n",
    "    ds = ds.map(map_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    # ds = ds.map(map_dual_targets, num_parallel_calls=AUTOTUNE)\n",
    "    # Không dùng .cache() để tiết kiệm RAM; chỉ prefetch\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99119d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sca_block(x, ratio=8, name=\"sca\"):\n",
    "    \"\"\"Simple Channel Attention: GAP -> 1x1 Conv (reduce) -> 1x1 Conv (gate sigmoid) -> multiply.\"\"\"\n",
    "    ch = int(x.shape[-1])\n",
    "    mid = max(ch // ratio, 1)\n",
    "\n",
    "    gap = layers.GlobalAveragePooling2D(keepdims=True, name=f\"{name}_gap\")(x)\n",
    "    red = layers.Conv2D(mid, 1, padding=\"same\", activation=\"relu\",\n",
    "                        use_bias=True, name=f\"{name}_reduce\")(gap)\n",
    "    gate = layers.Conv2D(ch, 1, padding=\"same\", activation=\"sigmoid\",\n",
    "                         use_bias=True, name=f\"{name}_gate\")(red)\n",
    "    out = layers.Multiply(name=f\"{name}_mul\")([x, gate])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5fdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model builder ==========\n",
    "def build_model(img_size=IMAGE_SIZE, freeze_backbone=FREEZE_BACKBONE):\n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    # Backbone EfficientNet-B4 (ImageNet)\n",
    "    base = EfficientNetB4(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    base.trainable = not freeze_backbone\n",
    "\n",
    "    x = base.output\n",
    "    # CBAM ở feature map cuối (nhẹ)\n",
    "    x = sca_block(x, ratio=8, name=\"sca\")\n",
    "\n",
    "    # Global pooling + head chung\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE)(x)\n",
    "    x = layers.Dense(DENSE_UNITS, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(DROP_RATE * 0.75)(x)\n",
    "\n",
    "    # Head A: Softmax 5 lớp\n",
    "    out_soft = layers.Dense(5, activation=\"softmax\", name=\"softmax\")(x)\n",
    "    # Head B: Ordinal (≥1..4), sigmoid\n",
    "    out_ord  = layers.Dense(4, activation=\"sigmoid\", name=\"ordinal\")(x)\n",
    "\n",
    "    model = models.Model(inputs, out_ord, name=\"EffB4_CBAM_DualHead\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24e5b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Compile ==========\n",
    "def compile_model(model,\n",
    "                  lr=LR,\n",
    "                  wd=WEIGHT_DECAY,\n",
    "                  ):\n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "   \n",
    "\n",
    "    losses = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "    metrics = [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                   metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81327a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Found 105145 files belonging to 5 classes.\n",
      "Found 3511 files belonging to 5 classes.\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# ================== MAIN ==================\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "ds_train = make_ds(TRAIN_DIR, subset=\"train\")\n",
    "ds_val   = make_ds(VAL_DIR, subset=\"val\")\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model = compile_model(model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a29a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Hàm mở block và train từng stage =====\n",
    "def unfreeze_blocks_by_prefix(model, prefixes):\n",
    "    \"\"\"Mở các block theo prefix như 'block6', 'block7'\"\"\"\n",
    "    for layer in model.layers:\n",
    "        if any(layer.name.startswith(pref) for pref in prefixes):\n",
    "            layer.trainable = True\n",
    "        elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "\n",
    "def run_finetune_stage(model, stage_idx, prefixes, lr, save_path):\n",
    "    print(f\"\\n=== Stage {stage_idx}: Unfreeze {prefixes} ===\")\n",
    "    unfreeze_blocks_by_prefix(model, prefixes)\n",
    "\n",
    "   \n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "\n",
    "    losses = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    metrics = [tf.keras.metrics.AUC(name=\"auc\", multi_label=True)]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses,\n",
    "                   metrics=metrics)\n",
    "\n",
    "    callbacks_ft = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(save_path, monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks_ft,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cf154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1: Train head (backbone frozen) ===\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13143/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - auc: 0.8718 - loss: 0.4054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 04:11:35.745192: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-15 04:11:35.865273: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - auc: 0.8718 - loss: 0.4054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 04:12:43.114002: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-08-15 04:12:43.261284: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1420s\u001b[0m 108ms/step - auc: 0.8718 - loss: 0.4054 - val_auc: 0.8317 - val_loss: 0.6257 - learning_rate: 3.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1693s\u001b[0m 129ms/step - auc: 0.9171 - loss: 0.3160 - val_auc: 0.8318 - val_loss: 0.6252 - learning_rate: 3.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1376s\u001b[0m 105ms/step - auc: 0.9252 - loss: 0.3002 - val_auc: 0.8185 - val_loss: 0.6515 - learning_rate: 3.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1383s\u001b[0m 105ms/step - auc: 0.9316 - loss: 0.2871 - val_auc: 0.8219 - val_loss: 0.7214 - learning_rate: 3.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1383s\u001b[0m 105ms/step - auc: 0.9358 - loss: 0.2787 - val_auc: 0.8051 - val_loss: 0.7045 - learning_rate: 3.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1397s\u001b[0m 106ms/step - auc: 0.9420 - loss: 0.2648 - val_auc: 0.8245 - val_loss: 0.6783 - learning_rate: 1.5000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1391s\u001b[0m 106ms/step - auc: 0.9442 - loss: 0.2600 - val_auc: 0.8266 - val_loss: 0.6470 - learning_rate: 1.5000e-04\n",
      "\n",
      "=== Stage 2: Unfreeze ['block6', 'block7'] ===\n",
      "Epoch 1/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2228s\u001b[0m 163ms/step - auc: 0.9412 - loss: 0.2602 - val_auc: 0.8600 - val_loss: 0.5728 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2077s\u001b[0m 158ms/step - auc: 0.9822 - loss: 0.1313 - val_auc: 0.8392 - val_loss: 0.8359 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m13144/13144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2053s\u001b[0m 156ms/step - auc: 0.9908 - loss: 0.0870 - val_auc: 0.8057 - val_loss: 1.0658 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m  770/13144\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:31\u001b[0m 153ms/step - auc: 0.9946 - loss: 0.0648"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/effb4_eyespacs2015_ordinal_v4_stage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mrun_finetune_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training pipeline completed ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mrun_finetune_stage\u001b[0;34m(model, stage_idx, prefixes, lr, save_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mlosses,\n\u001b[1;32m     22\u001b[0m                metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m     24\u001b[0m callbacks_ft \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     25\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     26\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m     27\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(save_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m ]\n\u001b[0;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stage definitions: mở block từ 7 → 1\n",
    "stage_blocks = [\n",
    "    [\"block6\", \"block7\"],\n",
    "    [\"block4\", \"block5\", \"block6\", \"block7\"],\n",
    "    [\"block2\", \"block3\", \"block4\", \"block5\", \"block6\", \"block7\"],\n",
    "]\n",
    "stage_lrs = [1e-4, 5e-5, 3e-5]\n",
    "\n",
    "# Stage 1 checkpoint\n",
    "stage1_path = \"models/effb4_eyespacs2015_ordinal_v4_stage1.keras\"\n",
    "\n",
    "if os.path.exists(stage1_path):\n",
    "    print(f\"Stage 1 checkpoint found: {stage1_path}, loading...\")\n",
    "    model = tf.keras.models.load_model(stage1_path, compile=False)\n",
    "else:\n",
    "    print(\"\\n=== Stage 1: Train head (backbone frozen) ===\")\n",
    "    history1 = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=10,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "            tf.keras.callbacks.ModelCheckpoint(stage1_path, monitor=\"val_loss\", save_best_only=True)\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(stage1_path)\n",
    "\n",
    "# Loop qua stage 2–8\n",
    "for i, (blocks, lr) in enumerate(zip(stage_blocks, stage_lrs), start=2):\n",
    "    save_path = f\"models/effb4_eyespacs2015_ordinal_v4_stage{i}.keras\"\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Stage {i} checkpoint found: {save_path}, loading...\")\n",
    "        model = tf.keras.models.load_model(save_path, compile=False)\n",
    "        continue\n",
    "\n",
    "    model = tf.keras.models.load_model(f\"models/effb4_eyespacs2015_ordinal_v4_stage{i-1}.keras\", compile=False)\n",
    "    run_finetune_stage(model, i, blocks, lr, save_path)\n",
    "\n",
    "print(\"\\n=== Training pipeline completed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc94b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipynb-py-convert structure_model_v4_for_eyepacs2015.ipynb structure_model_v4_for_eyepacs2015.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4561364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 12:01:28.442107: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-19 12:01:28.452767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755619288.466133   14061 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755619288.469958   14061 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755619288.479618   14061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755619288.479637   14061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755619288.479639   14061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755619288.479640   14061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-19 12:01:28.482911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 367 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755619290.736506   14061 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1446 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=models/effb4_eyespacs2015_ordinal_v4_stage3.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n\u001b[1;32m     14\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m     15\u001b[0m     TEST_DIR,\n\u001b[1;32m     16\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     seed\u001b[38;5;241m=\u001b[39mSEED\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ================== Load model ==================\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/effb4_eyespacs2015_ordinal_v4_stage3.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ================== Predict ==================\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# mô hình bạn build đầu ra là 4 sigmoid (ordinal), ta cần decode lại thành nhãn 0..4\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_ordinal\u001b[39m(y_pred_ord):\n",
      "File \u001b[0;32m~/Documents/DoAn/myvenv/lib/python3.10/site-packages/keras/src/saving/saving_api.py:200\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: filepath=models/effb4_eyespacs2015_ordinal_v4_stage3.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ================== Config ==================\n",
    "TEST_DIR = \"/home/duc/Documents/DoAn/aptos2019-blindness-detection/test_preprocess\"   # thư mục test gồm các sub-folder 0..4\n",
    "IMG_SIZE = 448\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "# ================== Dataset loader ==================\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=[\"0\",\"1\",\"2\",\"3\",\"4\"],\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=False,   # giữ nguyên thứ tự để so sánh\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# ================== Load model ==================\n",
    "model = tf.keras.models.load_model(\"models/effb4_eyespacs2015_ordinal_v4_stage3.keras\")\n",
    "\n",
    "# ================== Predict ==================\n",
    "# mô hình bạn build đầu ra là 4 sigmoid (ordinal), ta cần decode lại thành nhãn 0..4\n",
    "def decode_ordinal(y_pred_ord):\n",
    "    \"\"\" y_pred_ord: (N,4) sigmoid output\n",
    "        -> nhãn int 0..4\n",
    "    \"\"\"\n",
    "    return np.sum(y_pred_ord >= 0.5, axis=1)\n",
    "\n",
    "# Lấy ground truth\n",
    "y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "# Lấy dự đoán từ model\n",
    "y_pred_raw = model.predict(test_ds, verbose=1)\n",
    "y_pred = decode_ordinal(y_pred_raw)\n",
    "\n",
    "# ================== Classification report ==================\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# ================== Confusion matrix ==================\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
